# ğŸ“Œ Main Points

### 1. **Pod & Container Failures**
- Common errors: `CrashLoopBackOff`, `RunContainerError`, `OOMKilled`.  
- Causes: app crashes, misconfigured entrypoints, memory limits exceeded.  
- Fixes: check logs, correct configs, adjust resource limits.

### 2. **Image & Registry Issues**
- Errors: `ImagePullBackOff`, `ErrImagePull`, `InvalidImageName`.  
- Causes: wrong image names, missing credentials, malformed references.  
- Fixes: verify image URLs, registry secrets, use versioned tags.

### 3. **Configuration Errors**
- Errors: invalid env/config, missing `ConfigMap` or `Secret`.  
- Causes: misconfigured references or missing resources.  
- Fixes: correct references, recreate missing resources.

### 4. **Scheduling & Resource Problems**
- Errors: `PodUnschedulable`, `FailedScheduling`, `NodeNotReady`.  
- Causes: insufficient resources, taints, node failures.  
- Fixes: adjust node pools, affinities, quotas, restart nodes.

### 5. **Storage & Volume Issues**
- Errors: `PVC Pending`, `VolumeMountError`, `Multi-Attach error`.  
- Causes: no matching PVs, incorrect mount paths, conflicting volume usage.  
- Fixes: provision PVs, check access modes, detach conflicting volumes.

### 6. **Networking & DNS Failures**
- Errors: service unreachable, DNS resolution failed, Ingress 404.  
- Causes: misconfigured selectors, CoreDNS crashes, wrong Ingress paths.  
- Fixes: correct service specs, restart DNS, fix Ingress rules.

### 7. **Security & Access Problems**
- Errors: RBAC denied, unauthorized, PodSecurityPolicy violation.  
- Causes: insufficient permissions, policy conflicts.  
- Fixes: add proper roles, renew credentials, adjust policies.

### 8. **Deployment & Scaling Issues**
- Errors: rollout stuck, HPA not scaling, Helm release failed.  
- Causes: misconfigured probes, missing metrics-server, Helm chart errors.  
- Fixes: validate templates, install metrics-server, fix probes.

### 9. **Cluster & Node Failures**
- Errors: node disk full, API server unreachable, kube-proxy fails.  
- Causes: resource exhaustion, network/cert issues, corrupted iptables.  
- Fixes: clean logs, check control plane, restore iptables.

### 10. **Miscellaneous Errors**
- Errors: invalid YAML, job deadline exceeded, pod never terminates.  
- Causes: syntax errors, logic flaws, missing timeouts.  
- Fixes: lint YAML, optimize job logic, add termination checks.

---

### ğŸ¯ Key Takeaway
This document is a **Kubernetes troubleshooting handbook**:  
- Maps **errors â†’ root causes â†’ fixes**.  
- Emphasizes checking logs/configs first.  
- Validating resource references (images, secrets, ConfigMaps).  
- Managing cluster resources (nodes, memory, storage).  
- Ensuring networking, RBAC, and policies are correct.  
- Following best practices like versioned images, quotas, and monitoring tools.

---

- **k8s all errors list**[[click](https://drive.google.com/file/d/1u4Kyd5G8l6aCfMrrE8NI0XtKnA8__dNe/view?usp=sharing)]

![Image](https://cdn.prod.website-files.com/681e366f54a6e3ce87159ca4/68757f9e61edb27b795c9588_What-is-Crashloopbackoff-02.png)

# 1. ğŸ” CrashLoopBackOff

### What is CrashLoopBackOff?

* **CrashLoopBackOff** means a **Pod keeps crashing and restarting again and again**.
* Kubernetes tries to start the container.
* The container fails.
* Kubernetes waits a bit and **tries again** (back-off).
* This loop continues â†’ **CrashLoopBackOff**.

---

#### Why does CrashLoopBackOff happen? (Common Reasons)

* Wrong **command or entrypoint**
* Application **crashes at startup**
* Missing or wrong **environment variables**
* App canâ€™t connect to **DB / service**
* **Memory limit too low** (OOMKilled)
* Wrong **image or version**

---

### How Kubernetes behaves

1. Pod starts.
2. Container crashes.
3. Kubernetes restarts it.
4. Crash happens again.
5. Kubernetes slows down restarts â†’ *BackOff*

---

### How to check the issue

```bash
kubectl get pods
kubectl describe pod <pod-name>
kubectl logs <pod-name>
kubectl logs <pod-name> --previous
```

* **describe** â†’ shows events and errors
* **logs** â†’ shows application error

---

### ğŸ§  Very Easy Analogy (Interview Gold â­)

* **Pod** = Mobile phone
* **App** = App you open

ğŸ‘‰ You open the app
ğŸ‘‰ App crashes immediately
ğŸ‘‰ Phone keeps reopening it
ğŸ‘‰ Finally phone slows retries

That is **CrashLoopBackOff** ğŸ“±

---

### Simple Example

* MySQL Pod starts
* Password env variable is missing
* MySQL exits
* Kubernetes restarts it
* Result â†’ CrashLoopBackOff

---

### Why CrashLoopBackOff happens?

* Wrong command / entrypoint
* Missing environment variables
* App fails to start
* DB connection failure
* Wrong image


### How to fix it (Basic Steps)

* Check **logs**
* Verify **env variables**
* Increase **memory limits**
* Fix **command / image**
* Ensure dependent services are up

---

### ğŸ”‘ One-Line Summary

* **CrashLoopBackOff** = Pod is stuck in a crash + restart loop.

---

### â­ Interview Tip

Say this clearly:

> â€œCrashLoopBackOff occurs when a container keeps crashing on startup and Kubernetes repeatedly tries to restart it with a back-off delay.â€

---

![Image](https://miro.medium.com/1%2Ak1AllMAcwtEJiA0gTgMC7Q.png)

# 2. ğŸ”´ What is **OOMKilled**?

* **OOMKilled** means **Out Of Memory Killed**.
* Container used **more memory than its limit**.
* Kubernetes **kills the container immediately**.
* It is a **memory problem**.

### Why OOMKilled happens?

* Memory limit is too low
* Application uses more RAM
* Memory leak in application

ğŸ‘‰ Example:
Limit = 128Mi, App uses = 200Mi â†’ **OOMKilled**

---

### ğŸ†š OOMKilled vs CrashLoopBackOff (Clear Table)

| Feature             | OOMKilled             | CrashLoopBackOff            |
| ------------------- | --------------------- | --------------------------- |
| Problem type        | Memory issue          | App / config issue          |
| Reason              | Memory limit exceeded | App crashes on start        |
| Container killed by | Kernel / Kubernetes   | Application failure         |
| Restart behavior    | Killed immediately    | Repeated restart with delay |
| Common fix          | Increase memory limit | Fix config / logs           |

---

### ğŸ§  Very Easy Analogy (Interview Gold â­)

* **OOMKilled** = Phone battery full usage ğŸ”‹

  * App eats all RAM
  * Phone force closes app

* **CrashLoopBackOff** = Buggy app ğŸ“±

  * App opens
  * App crashes
  * Phone retries again and again

---

### ğŸ”§ How to Troubleshoot

### For OOMKilled:

```bash
kubectl describe pod <pod-name>
```

* Look for `OOMKilled`
* Increase memory limits

---

### For CrashLoopBackOff:

```bash
kubectl logs <pod-name>
kubectl logs <pod-name> --previous
kubectl describe pod <pod-name>
```

* Fix application error

---

### ğŸ”‘ One-Line Difference (Easy to Remember)

* **OOMKilled** â†’ memory exceeded
* **CrashLoopBackOff** â†’ app keeps crashing

---

### â­ Interview Tip

Say this clearly:

> â€œOOMKilled happens when a container exceeds its memory limit, while CrashLoopBackOff happens when a container repeatedly crashes during startup.â€

# ğŸš« `ImagePullBackOff`, `ErrImagePull`, `InvalidImageName`

These errors mean **Kubernetes cannot download the container image**.

---

## 1. ğŸ”´ `ErrImagePull`

### What it means

* Kubernetes **tried to pull the image and failed**.

### Common reasons

* Image name or tag is wrong
* Docker Hub / registry is down
* Private image but **no imagePullSecret**

### How to check

```bash
kubectl describe pod <pod-name>
```

---

## 2. ğŸ”´ `ImagePullBackOff`

### What it means

* Kubernetes **already failed many times** to pull the image.
* Now it **waits and retries slowly** (back-off).

### Important

* This usually comes **after `ErrImagePull`**.

---

## 3. ğŸ”´ `InvalidImageName`

### What it means

* Image name format is **invalid**.
* Kubernetes cannot even try to pull it.

### Examples of wrong names

* `nginx:` (tag missing)
* `Nginx` (case-sensitive issue)
* `nginx@@latest` (invalid characters)

---

### ğŸ§  Very Easy Analogy (Interview Gold â­)

* **Kubernetes** = Zomato delivery app
* **Image** = Food item

ğŸ‘‰ **InvalidImageName** = You typed food name wrong âŒ
ğŸ‘‰ **ErrImagePull** = Restaurant not reachable ğŸš«
ğŸ‘‰ **ImagePullBackOff** = App waits and retries â³

---

### ğŸ†š Quick Comparison Table

| Error            | Meaning                 |
| ---------------- | ----------------------- |
| InvalidImageName | Image name is wrong     |
| ErrImagePull     | Image pull failed       |
| ImagePullBackOff | Retrying after failures |

---

### ğŸ”§ How to Fix (Quick Steps)

1. Check image name and tag
2. Try `docker pull <image>`
3. Verify private registry credentials
4. Check network / proxy
5. Use correct `imagePullSecrets`

---

### ğŸ”‘ One-Line Summary

* **InvalidImageName** â†’ wrong image format
* **ErrImagePull** â†’ failed to download image
* **ImagePullBackOff** â†’ Kubernetes waiting before retry

---

### â­ Interview Tip

Say this clearly:

> â€œErrImagePull means image download failed, ImagePullBackOff means Kubernetes is retrying with delay, and InvalidImageName means the image name itself is wrong.â€

# âŒ Errors: **invalid env/config**, **missing ConfigMap / Secret**

These errors happen when a Pod **expects configuration**, but Kubernetes **canâ€™t find it or itâ€™s wrong**.

---

## 1. ğŸ”´ Invalid env / config

### What it means

* The **environment variable value is wrong** or **not usable**.
* App starts â†’ reads config â†’ **fails and exits**.

### Common reasons

* Wrong variable name (typo)
* Wrong value format (string vs number)
* Missing required env variable
* App expects config file but itâ€™s empty

### How it looks

* Pod may go to **CrashLoopBackOff**
* Logs show config or startup error

### Check

```bash
kubectl logs <pod-name>
kubectl describe pod <pod-name>
```

---

## 2. ğŸ”´ Missing ConfigMap

### What it means

* Pod refers to a **ConfigMap that does not exist**.
* Kubernetes cannot inject env or mount files.

### Common reasons

* ConfigMap not created
* Wrong name in Pod YAML
* Wrong namespace

### Example error

* `configmap "app-config" not found`

### Fix

```bash
kubectl get configmap
kubectl get configmap -n <namespace>
```

---

## 3. ğŸ”´ Missing Secret

### What it means

* Pod refers to a **Secret that does not exist**.
* Usually affects DB passwords, API keys.

### Common reasons

* Secret not created
* Wrong secret name/key
* Secret exists in another namespace

### Example error

* `secret "db-secret" not found`

### Fix

```bash
kubectl get secret
kubectl get secret -n <namespace>
```

---

### ğŸ§  Very Easy Analogy (Interview Gold â­)

* **Application** = Person
* **ConfigMap** = Instructions paper ğŸ“„
* **Secret** = Locker key ğŸ”

ğŸ‘‰ No instructions â†’ person confused
ğŸ‘‰ No key â†’ locker wonâ€™t open
ğŸ‘‰ Result â†’ work fails âŒ

---

### ğŸ§ª Quick YAML Example (Env from ConfigMap/Secret)

```yaml
env:
- name: DB_HOST
  valueFrom:
    configMapKeyRef:
      name: app-config
      key: database_url
- name: DB_PASSWORD
  valueFrom:
    secretKeyRef:
      name: db-secret
      key: password
```

---

### ğŸ”§ Troubleshooting Checklist

1. Check Pod events: `kubectl describe pod`
2. Verify names and keys (case-sensitive)
3. Ensure **same namespace**
4. Check logs for config errors
5. Create missing ConfigMap/Secret

---

### ğŸ”‘ One-Line Summary

* **Invalid env/config** â†’ wrong or missing values
* **Missing ConfigMap/Secret** â†’ referenced object not found

---

### â­ Interview Tip

Say this clearly:

> â€œThese errors occur when Pods reference incorrect or missing ConfigMaps or Secrets, causing applications to fail during startup.â€


![Image](https://img.site24x7static.com/images/without-set-requests-limits-consume-memory-resulting-failure-pod.png)

![Image](https://komodor.com/wp-content/uploads/2022/02/Kubernetes-Troubleshooting_-4.png)

![Image](https://labs.iximiuz.com/content/files/challenges/kubernetes-pod-debugging-part-1-ae00ba45/__static__/pod-lifecycle.png)

# âŒ `PodUnschedulable`, `FailedScheduling`, `NodeNotReady`

These errors mean **Kubernetes cannot place a Pod on any node** or **nodes are not healthy**.

---

## 1. ğŸ”´ `FailedScheduling`

### What it means

* Kubernetes **tried to schedule the Pod** but **no node matched the requirements**.

### Common reasons

* Not enough **CPU or memory**
* Node selectors / taints not matching
* Requested resources > node capacity
* PVC not bound
* HostPort already in use

### How to check

```bash
kubectl describe pod <pod-name>
kubectl get nodes
```

---

## 2. ğŸ”´ `PodUnschedulable`

### What it means

* Pod is in **Pending** state.
* Scheduler **cannot find a suitable node**.

ğŸ‘‰ This is usually the **status/result** of `FailedScheduling`.

---

## 3. ğŸ”´ `NodeNotReady`

### What it means

* Node is **unhealthy or unreachable**.
* Kubernetes **will not schedule Pods** on this node.

### Common reasons

* Kubelet stopped
* Disk / memory pressure
* Network issue
* Node rebooted or down

### How to check

```bash
kubectl get nodes
kubectl describe node <node-name>
```

---

### ğŸ§  Very Easy Analogy (Interview Gold â­)

* **Pods** = Passengers
* **Nodes** = Buses ğŸšŒ

ğŸ‘‰ **FailedScheduling** = No bus has empty seats
ğŸ‘‰ **PodUnschedulable** = Passenger waiting at bus stop
ğŸ‘‰ **NodeNotReady** = Bus is broken

---

### ğŸ†š Quick Comparison Table

| Error            | Meaning                    |
| ---------------- | -------------------------- |
| FailedScheduling | No suitable node found     |
| PodUnschedulable | Pod waiting (result state) |
| NodeNotReady     | Node is unhealthy          |

---

### ğŸ”§ How to Fix (Quick Steps)

1. Check node status (`kubectl get nodes`)
2. Reduce resource requests
3. Add more nodes
4. Fix taints / tolerations
5. Check PVC binding
6. Restart kubelet on node

---

### ğŸ”‘ One-Line Summary

* **FailedScheduling** â†’ scheduler canâ€™t place Pod
* **PodUnschedulable** â†’ Pod waiting to be scheduled
* **NodeNotReady** â†’ node is unhealthy

---

### â­ Interview Tip

Say this clearly:

> â€œThese errors indicate scheduling issues where either no suitable node is available or the node itself is not in a ready state.â€


# âŒ `PVC Pending`, `VolumeMountError`, `Multi-Attach error`


These errors are related to **storage (Persistent Volumes)** in Kubernetes.

---

## 1. ğŸ”´ `PVC Pending`

### What it means

* **PersistentVolumeClaim (PVC)** is created
* But **no PersistentVolume (PV) is available** to bind it

### Common reasons

* No PV exists
* StorageClass is missing or wrong
* Storage size mismatch
* Dynamic provisioner not running

### How to check

```bash
kubectl get pvc
kubectl get pv
kubectl describe pvc <pvc-name>
```

---

## 2. ğŸ”´ `VolumeMountError`

### What it means

* Volume exists, but **cannot be mounted inside the Pod**

### Common reasons

* Wrong mountPath
* Permission issues
* Node cannot access storage
* CSI driver issue

### Result

* Pod may stay in **ContainerCreating**
* App does not start

### How to check

```bash
kubectl describe pod <pod-name>
kubectl get events
```

---

## 3. ğŸ”´ `Multi-Attach error`

### What it means

* Same volume is being **attached to multiple Pods at the same time**
* Volume supports only **ReadWriteOnce (RWO)**

### Common scenario

* Using Deployment with replicas > 1
* Single PVC attached to multiple Pods

### Example error

* `Multi-Attach error for volume`

---

### ğŸ§  Very Easy Analogy (Interview Gold â­)

* **PVC** = Parking request ğŸš—
* **PV** = Parking slot

ğŸ‘‰ **PVC Pending** = No parking slot available
ğŸ‘‰ **VolumeMountError** = Slot exists but gate is locked
ğŸ‘‰ **Multi-Attach error** = One slot, two cars fighting

---

### ğŸ†š Quick Comparison Table

| Error              | Meaning                       |
| ------------------ | ----------------------------- |
| PVC Pending        | No volume available           |
| VolumeMountError   | Volume canâ€™t be attached      |
| Multi-Attach error | Same volume used by many Pods |

---

### ğŸ”§ How to Fix (Quick Steps)

1. Create correct PV or StorageClass
2. Match PVC size and access mode
3. Use **StatefulSet** for databases
4. Use one PVC per Pod
5. Check CSI driver & node health

---

### ğŸ”‘ One-Line Summary

* **PVC Pending** â†’ waiting for storage
* **VolumeMountError** â†’ storage mount failed
* **Multi-Attach error** â†’ volume used by multiple Pods

---

### â­ Interview Tip

Say this clearly:

> â€œThese errors occur due to storage issues like missing volumes, mount failures, or attaching the same volume to multiple Pods.â€

# ğŸŒ Networking Errors

## 1. ğŸ”´ Service Unreachable

**What it means**

* Service exists, but traffic **cannot reach Pods**.

**Common reasons**

* Service selector labels donâ€™t match Pod labels
* Pod is not running / not Ready
* Wrong Service type or port

**Check**

```bash
kubectl get svc
kubectl get pods --show-labels
kubectl describe svc <svc-name>
```

---

## 2. ğŸ”´ DNS Resolution Failed

**What it means**

* Pod cannot resolve service name (DNS issue).

**Common reasons**

* CoreDNS not running
* Wrong service name / namespace
* Network policy blocking DNS

**Check**

```bash
kubectl get pods -n kube-system
kubectl logs -n kube-system deploy/coredns
```

---

## 3. ğŸ”´ Ingress 404

**What it means**

* Ingress is reachable, but **path/host not matched**.

**Common reasons**

* Wrong host/path in Ingress
* Backend Service name/port wrong
* Ingress controller not running

**Check**

```bash
kubectl get ingress
kubectl describe ingress <ingress-name>
kubectl get pods -n ingress-nginx
```

---

# ğŸ” Security / Access Errors

### 1. ğŸ”´ RBAC Denied / Unauthorized

**What it means**

* User/ServiceAccount **does not have permission**.

**Common reasons**

* Missing Role/ClusterRole
* Missing RoleBinding/ClusterRoleBinding

**Check**

```bash
kubectl auth can-i get pods
kubectl describe rolebinding
```

---

### 2. ğŸ”´ PodSecurityPolicy Violation

**What it means**

* Pod violates **security rules**.

**Common reasons**

* Running as root
* Privileged container
* HostPath not allowed

**Fix**

* Update security context
* Use allowed settings only

---

# ğŸš€ Deployment / Scaling / Helm Errors

### 1. ğŸ”´ Rollout Stuck

**What it means**

* Deployment update **not finishing**.

**Common reasons**

* New Pods failing (CrashLoopBackOff)
* Readiness probe failing
* Image pull issues

**Check**

```bash
kubectl rollout status deploy <name>
kubectl describe deploy <name>
```

---

### 2. ğŸ”´ HPA Not Scaling

**What it means**

* Pods **not increasing/decreasing**.

**Common reasons**

* metrics-server missing
* CPU requests not set
* Low traffic / wrong threshold

**Check**

```bash
kubectl get hpa
kubectl top pods
```

---

### 3. ğŸ”´ Helm Release Failed

**What it means**

* Helm chart install/upgrade **did not succeed**.

**Common reasons**

* YAML error
* Resource already exists
* Missing values
* Permission issues

**Check**

```bash
helm status <release>
helm get all <release>
helm install --debug --dry-run
```

---

### ğŸ§  Super Easy Analogy (Interview Gold â­)

* **Service unreachable** â†’ Phone number correct, phone switched off ğŸ“µ
* **DNS failed** â†’ Name not in contacts ğŸ“’
* **Ingress 404** â†’ Wrong door in building ğŸšª
* **RBAC denied** â†’ No office access card ğŸš«
* **Rollout stuck** â†’ New staff not joining ğŸ§
* **HPA not scaling** â†’ Manager canâ€™t see workload ğŸ“Š
* **Helm failed** â†’ App installer crashed ğŸ’¥

---

### ğŸ”‘ One-Line Summary

* Network errors â†’ traffic/DNS/Ingress issues
* Security errors â†’ permission/policy issues
* Ops errors â†’ rollout, scaling, Helm problems

---

### â­ Interview Tip

Say this clearly:

> â€œMost Kubernetes errors fall into networking, security, or deployment categories, and the first step is always checking `kubectl describe`, logs, and events.â€
